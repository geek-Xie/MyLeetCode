<center><h1>MySQL面试笔记</h1></center>

### 1. 为什么在生产环境下，要给字段设置为NotNULL，然后必须要有default？

​	因为在Innodb的行格式里，有NULL值列表，每当表中有一个字段为NULL，那么NULL值列表就会有一个二进制位，有n个字段允许为NULL，则意味着有n个二进制位，那么每一行存储的数据就得要额外的空间来做为NULL值列表的存储，**所需要的字节数为n/8**    , 举个例子来说如果有10个字段允许为NULL，则每一行就得需要2个字节来维持这个NULL值列表，如果这张表有5个字段允许为NULL，那么每一行就得需要1个字节来维持。这样随着表的数据量越来越大，就会需要耗费大量的空间去存储NULL值，造成了磁盘浪费。

----

### 2. 如果CHAR(10),但是存储了 'abc'，那么它是怎么存储的？

​    如果它的存储长度不到10的话，那么会用空格补齐到10 ，也就是：‘abc       ’

----

### 3. 页内根据主键查询流程

​	在回答这个问题的时候，我们首先需要知道在这一个16K的页中，它里面的存储了什么数据？这些数据是怎样存储的？这些页除了我们往里面塞得数据之外还有两条数据是Infimun与Supremum。**前者是这个节点的最小记录，后者是这个节点的最大记录**，这两条记录并不会具体的去存储值，而是我们人为规定的两套数据。在这些叶子节点中我们的数据被分为一个个的槽，每个槽由1~8条数据构成除了(Infimum记录单独为一个槽)，槽与槽之间的记录时挨着的，槽内的记录是**根据主键值从小到大进行排序的**。每个槽会有一个编号，第一个槽永远是  Infimum记录独占一个槽即0号槽，然后从0号槽开始对槽进行排序，查的时候就会先去找中间的槽，然后看这个值和上面那个槽的最大值和下面那个槽的最小值进行比较，如果比最大值小就继续找中间值。一直找到那个值所在的槽的时候就会从这个槽 的最小值开始遍历，一直到那个值为止。

​	举个栗子：   先给数据库插入20条数据，id是1~20，这个时候在一个内存页里，它会被分割成5个槽`InfiMun单独一个槽，剩下的槽每到8个会被裂变成两个槽，一个是4 一个是5，这样的话所有槽的大小就是 1  4  4  4  7`.   如果我想去查id为6的数据的话，它首先先会找中间的槽  (0+4)/2 这时候就会找到2号槽，2号槽的的主键是8，比6大，接着继续找中间的槽(0+2)/2， 1号槽的主键是4，所以就可以确定这个主键是在2号槽中，然后进入到这个槽，从第一条数据向后遍历，一直知道id为6的数据为止。

----

### 4. 索引没有按照我们预想的执行怎么办

​	对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。

----

### 5. InnoDB索引查找的流程

​	InnoDB的数据存储结构使用B+树来进行存储的，我们将这棵树的节点称之为页，每个页默认为16K的大小。这些页都会被用来存储数据(***这里的数据分为用户数据与目录项数据***)。 为了尽可能地存储更多的数据，让查询速度更快，更稳定，B+树的节点被分为了两种，第一种是非叶子节点，第二种是叶子节点。我们会用非叶子节点来存储**目录项数据**，用叶子节点来存储我们的**用户数据**。

​	目录项数据就是我们查找的时候内部用的索引，它是由单向链表组成。这个单向链表中包含着两个值，一个是id，一个是页数，即id-page。id是page的最小id，这个page并不是连续的，所以有可能是  1/2 ->5/20  (为了方便文字书写，分子是id，分母是页数)，即 页数为2的最小id是1，页数为20的最小id为5.然后同级的页使用双向链表链接。

​	当我们在优化sql查询速度的时候，第一个想法就是索引。那么索引它是怎么去查找的呢？现在我们常用的数据库引擎是InnoDB，它的索引实现默认是B+树来进行实现的。每一个索引都是一个B+树，这里的索引实现由多种，第一种是**主键索引**，第二种是**二级索引**，第三种是**联合索引**

​	**主键索引查找流程**，因为主键索引里面包括了所有的数据，它是先去根目录去找目录项页，找到id与这个目录项页的id大并且比下一个目录项页的id小的时候就找到 这个目录项页的下一级，然后继续找，重复这个过程。找到这个id所在的页之后就可以使用我们在 3 里面写的那样根据槽来找记录，最后返回

​	**二级索引查找流程**，二级索引也是一棵B+树，不过相对于主键索引的树来说它里面存的东西比较少，存的并不是所用的用户数据，而是这个二级索引+主键索引。找到符合的值的时候，就去根据这个主键id找到这个id在主键索引的位置，这个根据二级索引找到主键索引再从主键索引找到相应的数据的过程叫做**回表**。所以二级索引相对主键索引来说比较慢，因为它有一个回表的过程，更主要的是 **每找到一条符合的记录就会回一次表**。还有一个问题就是在目录项页中，它的组成应该是三种 二级索引的那个值+主键值+页号，当二级索引的那个值相同的时候他就会去比较主键值。

​	**联合索引查找流程**，联合索引会根据你创建联合索引时列的顺序来构造B+树的，加入我用a·v来构建一个联合索引的话，它会先把各个记录还有页根据a来进行排序，然后在a排序相同的情况下，再去排b的顺序。所以联合索引只是建立一棵B+树而不是建立多个B+树。

----

### 6. MyISAM的索引是咋样的

​	对于MyISAM来说，它不像InnoDB的聚簇索引即数据，它是将索引和数据分开，它会将这些数据根据**插入的顺序**来对这些数据进行排序，然后把这些写到了一个文件中。当建立索引之后，它会维护一个行号和主键的关系，当我们需要查找一些数据的话会先找到这个主键，然后找到这个主键对应的行号，再从数据文件中找到这个行号对应的数据。这个过程是不是听着有点耳熟，没错它就是我们在上面提到的回表，也就是说在MyISAM中，不论我们用哪种索引都要进行回表操作。

----

### 7. 使用索引的代价

####    - 空间代价

​	 	每建立一个索引就需要一个B+树，B+树的每个节点默认是16K，如果建立多个索引就需要建立多个B+树，也就会浪费更多的空间。

####    - 时间代价  

​		MySQL索引是一棵B+树，在我们对数据进行增删改的时候就需要对这个B+树进行操作，这里就有可能对节点和记录的这些排序造成破坏在这个过程中就有可能导致页分裂、页回收等操作

​		执行计划，MySQL 在执行SQL的时候，它需要生成一个执行计划，因为它没有我们想象的那么智能，甚至有时候还是个智障。在执行计划生成的时候，它需要计算使用不同索引所需要的成本，然后选择成本比较少的那个计划。如果索引过多的话，这里的生成执行计划就得需要一段时间，导致我们的查询时间过长。

----

### 8. order by 、like、limit的顺序是什么

​	```select * from table where id>0 and b like 'r%' order by id limit 10;```

​	顺序为 like -> order by -> limit

----

### 9. order by条件为索引的时候，在什么时候不会使用到索引

- 在联合索引中，如果order by的顺序不符合联合索引的顺序的时候不会用到索引。比如 a_b_c为联合索引，我这时候如果使用了 order by c,b,a  、 order by b ,c等等不符合联合索引规则的时候就不会使用联合索引

- ASC、DESC混用的时候 
- order by条件里面存在非索引的时候

- where用的索引与order by 用到的索引不一致时   

- order by条件用到函数的时候

可以为上面的五条各举一个栗子

```sql
1. select * from table order by b;
2. select * from table order by a,b desc;
3. select * from table order by key1;
4. select * from table where d >10 order by e;
5. select * from table order by upper(e);
```

----

### 10. 什么时候创建索引比较好？

- 对于where条件、order by条件、group by条件去创建索引

- 这个列的基数比较大，基数即这个列不重复的数

- 类型尽量小(即这个列的类型占用空间尽可能地小)

  ​	在创建索引的时候是需要创建B+树的，我们把类型尽可能的选择小一些的话占用的空间也会小很多。

- 前缀索引  即选择对这个索引的前n个值来进行创建，我们可以选择一些值来做索引的长度，然后看这个列的基数，然后在长度和基数之间做平衡，当然基数最大的就是全索引，但是也会相对的耗费一些内存。SQL如下   ：`select count(distinct left(e,4))as L4,  count(distinct left(e,5))as L5,  count(distinct left(e,6))as L6,  count(distinct left(e,7))as L7  from table`

- 覆盖索引，既让select的条件少到不需要回表的时候，  `select d from table where d>10;`

- 索引不要去做数学计算，但是常数却可以做数学计算  `①  select * from table where d+1>10;     ②  select * from table where d>9;` 因为2会去走索引，而1不会

- 尽量不要发生页分裂  让主键自增

- 尽量不要冗余索引

----

### 11. 在一个空表里面，不断往表里插入数据，这个时候MySQL的存储空间是如何变化的

​	首先，我们需要明确一点就是在InnoDB引擎中，MySQL的所有数据都是在B+树中存储的，哪怕你没有显示的去创建索引，这个B+树还是会创建的。

​    在一个空表里，它的B+树就是一个根节点，这个节点是一个没有数据的空节点。随着不断往表里新增数据，这个根节点会不断的新增数据，直到根节的可用空间已经不足以分配新数据时，它会新建一个节点，把所有的数据复制给新的节点。接着再将这个页进行分裂操作，就可以得到另外一个新页，新的数据就会根据主键来判断是存储到哪个页面中。原本的根节点就会升级，从原本的存储用户数据的页面转为目录项页，然后把两个页的目录项插入到根节点中。后续数据量不断增加，就会重复着上面的操作。

PS：不论任何变化，根节点的页值都是不变的，它会将根节点的页值存起来，下一次再进行查询的时候，就会取出这个根节点的页值，访问到根节点。

----

### 12. MyISAM使用索引与InnoDB使用索引有什么不同吗？

​	MyISAM的索引存储和InnoDB不太一样，在InnoDB中，索引就是数据，比如聚簇索引。但是MyISAM的话索引和数据是两种不同的文件，数据文件是将所有的数据按照**插入的顺序**全部存入到一个文件中，这样就有可能导致我这个数据文件的存储的数据不是按照id大小来排列的。这也就意味着在这个数据文件查找数据的时候是无法使用二分法进行查找的，速度也就相对于InnoDB来说慢一些。MyISAM的索引文件是给表的主键单独新建一个文件，用主键值和行号进行存储的。也就是说先根据这个主键值查到行号，再根据行号在数据文件中找到这条数据。这也是一种徽标的操作。

----

### 13. Buffer Pool是什么？

  	在MySQL中，我们所有的用户数据都存在磁盘中，但是磁盘的速度吧，懂得都懂。所以为了效率，MySQL会将你查询的页从磁盘里搂出来之后加载到内存中。这样不仅不需要每次都要从磁盘中找数据，而且也减少了磁盘IO次数。 `哪怕你在这个页面只查了一条数据，MySQL同样会将这个页面从磁盘中取出来缓存到内存中。`存储这些页面数据的内存块就是BufferPool，在这个内存块中的数据页叫做缓冲页。如果这个缓冲页没有被加载，那么这个缓冲页就是一个空闲的缓冲页。

- 如何找到相应的缓冲页？

  ​	  在BufferPool中，每一个缓冲页都有一个相对应的控制块，可以通过这个控制块去找到这个缓冲页。为了可以方便的区分哪些缓冲页被使用了，哪些缓冲页可以用，MySQL维护了一个叫做**Free链表**的双向链表，每个节点存放着空闲缓冲页对应的控制块。再定义一个存储头节点，尾节点，节点数量信息的基节点，头节点指向了第一个缓冲页的控制块，最后一个控制块指向了尾节点。每当有一个数据页被加载到缓冲区的时候，free链表就会少一个节点。**所以free链表总是表示着当前有多少空闲的缓冲页**

  ​	  当我们想要读取某个页的数据时，怎么判断这个页是否在缓冲页中？mysql维护了一个哈希表，key为表空间号+也好，value为当前缓冲页的控制块。所以就可以通过表空间号和页号作为key，在哈希表中能否找到这个缓冲页，如果找到了就可以直接在这个缓冲页读取值，如果没有找到的话就在Free链表中选一个空闲的缓冲页来加载数据。

- 如果我缓存的数据被修改了，它会怎么变呢？

  ​	    既然用到了缓存，那么就必须要考虑到数据一致性问题。如果有修改语句修改了缓冲页的数据怎么破？当修改了某个缓冲页的时候，就可以理解为这个缓冲页已经是一个**脏页**，对于这种脏页我们不能每次都要刷一下磁盘，因为频繁刷磁盘是一件很耗费性能的事情。

  ​	    对于这个问题，MySQL同样维护了一套双向链表来保存脏页，这个链表叫做**Flush链表**,我们并不会立即将这个脏页刷新到磁盘中去，而是先挂在Flush链表中，**在某一个时间点统一去刷新**，这样就会避免频繁的刷磁盘。Flush链表和Free链表非常类似，都有同样的基节点。

----

### 14. 如果发生了全表扫描，BufferPool会怎么办？

​	BufferPool毕竟是一个固定大小的内存空间，也就意味着这个内存空间有可能会被用完，如果Buffer Pool空间不足了，还有新的页面被读取到缓冲页怎么办？这里用了LRU的方式，当我们使用了某个缓冲页的时候就把这个缓冲页放在头部，当空闲的缓冲页用完之后就把最后使用的淘汰。

​    当然这个只是看起来很美好，现实却是非常的残酷。因为InnoDB有一个神奇的操作叫做预读。当你访问某个页的时候，它会将这个页后面的x页一块加载到Buffer Pool中。`这个x我们可以在系统变量中进行设置。`如果能用到还好，但是用不到的话那就很尴尬了。如果Buffer Pool设置的比较小，还加载了预读的页面到Buffer Pool中，就会导致Buffer Pool的命中率降低。或者有时候因为我们的SQL导致全表查询，这样就会产生 “会把其他语句执行会用到的页给挤出去，等到需要的时候再拉进来”，这种更加尴尬的局面。 总结一下就是 **加载了许多没有被用到页和少访问量的页挤掉了高访问量的页**。

​    为了解决这两种尴尬的局面，将链表分为两部分。存储高访问量缓冲页的young区和低访问量缓冲页的old区。前者就是我们常说的**热数据**，后者时我们常说的**冷数据**。

​    解决预读导致链表增加了许多无用缓冲页的方式就是，当我们在第一次加载到缓冲页的时候，它会加载到old区的第一位，后续预读的那些页面也会被慢慢的从old区逐出

​    解决全表扫描导致加载了许多低访问量的缓冲页的方式是，第一次加载到old头部区域的缓冲页的时候，在一定的时间内再次访问的话，不会把这个页放在young区，如果再次访问的时间超过了这个时间就会把这个缓冲页放在young区。

----

### 15. 事务

​	什么是事务？**一个或者多个满足ACID的 数据库操作，统称为事务。**只有当事务提交并且刷新到磁盘或者事务法生回滚进入到中止状态才算一个事务已经结束了。

- 原子性(Atomic)

  原子性就是一个操作集合不可分割，通俗点就是我们常说的“要么都执行，要么都不执行”.如果执行过程中发生错误，那么整个事务过程都会回滚，和这个事务从来没有执行过一样。**由undo 日志来保证**

- 一致性(Consistency)

  事务开始和事务结束时，数据处于一致的状态。我们的数据库对应着我们现实世界的映射，在符合现实世界的映射情况下满足原子性和隔离性的操作就是一致性。

- 隔离性(Isolation)

  两个事务之间是不可见的，我们常说的事务隔离级别就是隔离性的一种具象化体现。隔离性在InnoDB中可以分为四个等级，序列化—>可重复读—>读已提交—>读未提交 。  **由MVCC保证**

- 持久性(Durability)

  当一个状态已经成功结束转换完之后，这个结果会被永久保留。**由redo日志来保证**

----

### 16. redo log

​	我们提交事务之后，在事务中做的修改操作并不会立即的去刷新到磁盘，因为在InnoDB中，磁盘刷新的单位是以页计算的，每个页的大小是16K，如果我们因为在A页里改了一个字节，然后再将整个页刷新到磁盘中，这是一种得不偿失的措施，这样会造成很高的资源浪费。而且有时候，我们的修改语句可能会修改多个页的数据，或者修改很多不相邻页的数据,当把这些修改后的缓冲页刷到磁盘中会进行很多随机IO,而且随机IO也是一个非常浪费资源的操作.

​	这个时候redo log就诞生了,当我们在事务中修改某个页的数据之后,它不会立即刷到磁盘中,而是会记录在redo log日志中,就像下面的记录方式: 

`修改2号表空间30页偏移量为2000处的值更为10086.`

​	这样的话,当事务提交后发生了系统崩溃的时候,刚刚提交的数据也不会消失,因为刚刚提交的数据已经记录在redo log中,当数据库重新启动之后会重新的去读取redo log日志,将这些修改操作更新到磁盘中,这样就可以保证了持久性,而且因为redo log是顺序写入磁盘的,使用了顺序IO,相比之前的随机IO要快很多.

​	将一条数据插入到页A的时候,发现页A已经没有多余的空间再去容纳一条数据了，这个时候就得需要裂变页，然后把原先的页的一部分数据复制到新的页中,然后将这个新的页插入到叶子链表中,在目录项页里面增加一条指向新页的记录. 如果在这个中间,redo log只记录了一部分,那在程序崩溃后恢复的时候就会一棵不正常的B+树,这对于数据库来说是不能容忍的.所以这里增加了一个小组的概念,要么把这组记录全部恢复,要么把这组数据全部不恢复.这个小组叫做**Mini-Transaction**.是在redo log中增加一个标识位,执行redo log的时候,只有看到这个标记结尾的时候才会进行恢复. 

​	用官方一点的话来说Mini-Transaction 就是对底层页面进行一次原子性访问的过程.简称为**MTR**,一个事务中有多个语句,每个语句都会有多个MTR,每个MTR都会有多个redo log

----

### 17. redo log buffer

​	和上面的Buffer Pool产生的条件一样,为了不让每次产生redo log就往磁盘刷,它会有一个redo log buffer,这个buffer被分为多个 redo log block,每个redo log block 就是一个512K的页,写完一个block之后,就会写入到新的block中.有的MTR可以占用多个block,而有的block却可以容纳多个MTR.

​	因为redo log并不会直接的刷到磁盘中,所以这里有一个全局定位的变量叫做 **flushed_to_disk_lsn**,它是为了表示当前刷入磁盘的索引.

### 18. redo log 的check point

​	当redo log 已经刷到了磁盘中，哪怕系统重启了，也不需要redo log来恢复数据了。所以当前的redo log占用的空间也可以被后面的redo log重用了。所以说当redo log对应的脏页已经被刷到了磁盘中之后，那么这个redo log也就可以被覆盖了。这个时候会有一个全局的变量checkpoint_lsn来记录当前可以被覆盖的redo log总量。脏页a被刷到磁盘上之后，那一次mtr生成的redo log日志也就可以被覆盖了，然后更新一下checkpoint_lsn。这样一个流程就被叫做执行了一次checkpoint。但是有一点需要注意，就是刷新一次脏页并不代表着一定会执行一次checkpoint，这两者之间的运行没有必然的联系。因为它们是在不同的线程中执行的，而且刷新一次脏页喝执行一次checkpoint所消费的资源也是不同的。
​    当系统更新页的速度特别快，就会导致写redo log的次数也会频繁。如果后台线程没有办法及时的将这些脏页刷到磁盘中，系统也就灭有办法及时的取执行checkpoint。所以就得需要用户线程取干预，让用户线程取将flush'链表中最早修改的脏页刷新到磁盘中，这样就可以执行checkpint操作

### 19. 当服务器宕机之后,如何恢复数据.

#### 	- 确定恢复的起点

​        	找到最近发生的checkpoint_lsn，就可以确定恢复的起点。

####     - 确定恢复的终点

​    		我们前面提到过block，每一个block都有512，只有当前的512K被写完之后，才会往下一个block写。所以		就只需要恢复到不满足512K的block中。

#### 	- 恢复

​			MySQL会准备一个哈希表，**用表空间号+页号作为key，将表空间号和页号都相同的redo log作为value**，		如果一个key下面有多个value的话，就把这个redo log以生成时间的顺序用链表连接起来。这样遍历整个哈希		表	就可以将所有的页恢复。而且还可以避免很多随机IO，因为我们可以一次性的将一个页修复好。

### 20. undo 日志

​	事务是需要保证原子性的，也就意味着一组事务操作中，要么全部执行成功，要么全部执行失败。如果我们在执行事务的过程中，突然数据库所在的服务器宕机了，或者我们手动的执行了rollback了，就得需要把我们的数据恢复到修改到事务之前的样子。当我们在插入的时候，需要记录主键ID，当我们在删除或者修改的时候，需要把旧的值记录下来。这样在回滚的时候就可以保证事务开始前和回滚开始后的数据是一致的。**记录这些操作的日志就被叫做 undo log**。

​    不论是只读事务还是读写事务在进行增删改操作时都会分配一个trx_id(因为只读事务是可以修改临时表的，所以只读事务也是会进行增删改操作的)。这个trx_id就是事务ID，它是一个全局性的变量，每当产生一个事务的时候，就会先把这个值赋给这个事务作为事务ID，然后这个值在进行自增。

​	undo日志有一个roll_pointer的指针，这个指针就像版本链一样，可以通过这个指针指向上一条的undo 日志操作。这样我们在一个事务中的undo日志就可以通过 这个roll_pointer指针来追本溯源，找到最开始的那条记录。

​    我们的undo 日志是有类型的区分，大体可以分为三种，对应着我们的增删改。

- **新增时的undo 日志记录**

  ​    有一个TRX_UNDO_INSERT_REC的日志类型，会生成一个undo no(undo 日志对应的编号)，然后记录下主键的占用的存储空间大小和主键的值。

- **删除时的undo日志记录**

  ​    在事务还未提交时，仅把记录的delete_flag标识设置为1，等到事务提交之后，就会把这条记录移到垃圾链表中(一块可以重复使用的存放已经被删除数据的链表)。这个过程被称为**purge**。

  ​    在前面说的，删除操作会有两个步骤，分为事务提交之前和事务提交之后。在undo 日志中我们只需要关注事务提交之前所做的操作就好，有一个TRX_UNDO_DEL_MARK_REC的日志类型，记录下被删除列的trx_id和roll_pointer等隐藏列还有该列的一部分主键信息，比如占用的存储空间大小、主键的值以及该列在记录中的位置。

- **修改时的undo日志记录**

  ​    这里相对新增和删除而言有点不太一样，因为这里需要区分两种情况，不更新主键和更新主键

  - 不更新主键

    ​    如果修改之后的记录和原本的记录大小一致的话，就可以**直接更新**，但是修改之后的记录和原本的记录大小不一致的情况下，就得需要**先删除旧记录，再插入新纪录**。这里的删除不是前面的先将记录的delete_flag标识为1，而是直接把这个链表加入到垃圾链表中。

    ​    这里的日志类型叫做TRX_UNDO_UPD_EXIST_REC，它会记录下这条语句执行之后，会有多少列被更新，然后记录当前列的主键位置，更新前该列的大小，更新前该列的实际值，然后看是否更新索引列来决定加不加索引列各列的信息。

  - 更新主键

    ​    我们知道，我们的数据是以聚簇索引的方式来存储的。在聚簇索引中，记录会按照主键值的大小来连接成一个单向链表。当我们在更新主键的时候就意味着当前记录在聚簇索引中的位置会被改变。对于这种形式的修改语句，也是分为两个步骤。第一个步骤就是和前面一样，只是将记录的delete_flag标识设置为1，将更新后的值创建一条新的记录，然后插入到聚簇索引中。

    ​    这里的日志记录会记录下两条记录，一条是TRX_UNDO_DEL_MARK_REC第二条是TRX_UNDO_INSERT_REC，也就是说会记录一下删除操作和新增操作

  将这些不同类型的undo日志分为两个大类，一个是新增一个是修改，新增就是我们新增和修改主键值时产生的undo日志，其他的操作都可以归为修改。**这两种操作不能在一个页面中共存**。

### 21. MVCC

#### - MVCC使用场景

​	MVCC的中文名称叫做多版本并发控制，是基于undo log做的一种解决读写锁导致的多个长时间读操作让写操作饿死一种机制，简单地说就是解决了并发情况下的读写冲突，相对读写锁而言，效率更高。在InnoDB中因为读未提交直接读取到最新的数据版本，而串行化则都是使用锁来进行操作，所以也就不需要MVCC来控制。所以MVCC只用在了**读已提交**和**可重复读**。

#### - 版本链

​	在聚簇索引中，每一条记录都会有两个隐藏属性，分别是**trx_id**和**roll_pointer**，前者是当某个事务对这条记录做出改动时，会把事务ID记录下来，后者是当事务对这条数据进行修改时，它会将旧记录记录到undo日志中，然后用roll_pointer指针串起来，形成版本连。我们就可以通过当前的记录的roll_pointer去寻找它之前的修改记录.

#### - Read View

​	对于读已提交和可重复读这两种级别的事务，我们必须要保证读到已经提交修改事务的数据，如果事务A修改数据后还未提交,那么事务B就不能读取到事务A修改过的数据.所以就得需要判断记录中版本链是不是当前事务可见的.这里就出现了一个ReadView的概念.

- m_ids

  ​	在生成ReadView时,当前系统中活跃的读写事务ID列表

- min_trx_id

  ​	在生成ReadView时,当前系统中活跃的读写事务最小事务ID

- max_trx_id

  ​	在生成ReadView时,系统要分给下一个事务的事务ID,这里并不是最大的事务ID ,因为事务ID是一个不断自增的值.

- creator_trx_id

  ​	在生成ReadView时,创建该ReadView的事务ID.

当访问版本的trx_id和ReadView的creator_trx_id相同时,就代表着当前事务正在访问当前事务修改过的值,所以是可以访问到的.

当访问版本的trx_id<min_trx_id时,就代表着当前事务创建的时候,这个被访问的事务已经提交了,所以可以访问到当前版本

当访问版本的trx_id>max_trx_id时,就代表着被访问的事务在当前事务创建之后才创建的,所以无法访问

当访问版本的trx_id>min_trx_id && trx_id<max_trx_id时,就得需要判断trx_id在不在m_ids中,如果不在m_ids中就代表着访问的时候,这个版本已经提交了,可以访问,如果在m_ids中,就以为这个版本还未提交,所以不能访问.

如果不能访问数据的话,就会根据版本链去查上一个版本,如果上一个版本的数据可以被访问到,就直接用上一个版本的数据,反之则会不断往上面查,一直会查到最早的哪个版本.

#### 读已提交和可重复读的区别

​	对于读已提交而言,它每次访问数据都会生成一个ReadView,而可重复读只会使用第一次访问数据生成的ReadView,所以读已提交会出现不可重复读的问题.

### 22. 锁

​    锁是一种解决并发问题的一种思想，对于读-读操作，读-写操作，写-写操作这三种可能导致数据一致性问题的一种解决方式。

​	在MySQL中，锁是一种内存的结构，在事务执行之前是没有锁的，等到对事务有所改动的时候就会看这条记录有没有关联的锁结构，如果没有的话就需要生成一个锁结构与这条记录做出关联。

- 加锁成功，在内存中产生了对应的锁结构，而且锁结构的is_waiting属性为false时，就代表着这个事务可以继续执行操作。

- 加锁失败，在内存中产生了对应的锁结构，而且锁结构的is_waiting属性为true时，代表着这个事务需要进入等待状态，等待加锁成功的事务释放这把锁，将这条记录对应的锁结构的is_waiting改为false就可以获取这个锁了。

- 不加锁，直接执行操作，不在内存中产生对应的锁结构。

#### - 共享锁和独占锁

- 共享锁，又被叫做S锁。对于共享锁来说，A事务已经获取到这条记录的共享锁的时候，B事务再去获取这条记录的共享锁，也是可以获取成功的。但是如果B事务获取这条记录的独占锁的时候，也是不能获取成功的，必须得要等到A事务释放这条记录的共享锁才可以。
- 独占锁，又被叫做X锁。对于独占锁而言，A事务获取到某条记录的独占锁的时候，B事务无论如何也不能获取到这条记录的独占锁或者共享锁，必须得要等到A事务释放这条记录的独占锁才可以。

##### - 意向锁

​	**意向锁是一个表级锁**，它表示**意图**去获取这个表的锁。凡是要获取某条记录或者某个表的共享锁，就必须要先获取这个表/行的意向共享锁。这样就可以解决，A事务已经获取了表中的某行记录的共享锁，B事务想要获取表中的独占锁，这个时候就得要保证没有任何事务获取到了这个表的锁。但是如果每一行去遍历那就很烦了，所以就有了意向锁的产生。简单地说，**它避免了用遍历的方式来查看这张表有没有上锁的记录**。

- 意向共享锁，又被叫做IS锁。事务要获取表中的某行记录或者整张表的共享锁的话都得要先获取这个表的意向共享锁。当事务A想要获取这张表的意向共享锁时，发现这张表已经有**X锁**了，就无法去获取这个表的意向共享锁，得要等到X锁被释放之后，就可以去尝试获取这个这个表的意向共享锁了.
- 意向独占锁，又被叫做IX锁。事务要获取表中的某行记录或者整张表的独占锁的话就得要获取这个表的意向共享锁,事务A想要获取这张表的意向独占锁时,发现这张表已经有**X锁或者S锁**时,就无法去获取这个表的意向独占锁，得要等到锁被释放之后，就可以去尝试获取这个这个表的意向独占锁了.



|  锁类型  |    S锁     |    X锁     |    IS锁    |    IX锁    |
| :------: | :--------: | :--------: | :--------: | :--------: |
| **S锁**  |  可以兼容  |  不可兼容  |  可以兼容  | 不可以兼容 |
| **X锁**  |  不可兼容  |  不可兼容  | 不可以兼容 | 不可以兼容 |
| **IS锁** |  可以兼容  |  不可兼容  |  可以兼容  |  可以兼容  |
| **IX锁** | 不可以兼容 | 不可以兼容 |  可以兼容  |  可以兼容  |

##### - 如何给这条记录加锁

```sql
SELECT * FROM table WHERE id = 1 Lock IN SHARE MODE;     --给读语句增加共享锁
SELECT * FROM table WHERE id = 1 FOR UPDATE;             --给读语句增加独占锁
```

##### - 如何给整张表加锁

```sql
LOCK TABLES user READ     -- 给user表增加表锁级别的共享锁
LOCK TABLES user WRITE    -- 给user表增加表锁级别的独占锁
```



#### - 行锁

行锁就是对某条记录加上锁。

我们常用的InnoDB引擎，支持行锁.相比较表锁,它的粒度更细，占用的资源更加少。对于只需要锁几条记录的情况下，行锁比表锁性能更加好。下面是行锁的一些分类。

##### - record lock

​	普通的行锁，有共享锁和独占锁之分。和前面聊的很像。

##### - gap lock

​	为了解决幻读问题而被设计出来的一种锁。如果对某条记录加了gap锁的话，就不能允许在上一条记录和这一条记录之间增加数据，而且也不能给最后一条数据后面增加记录。举个栗子：对于一张表A，有下面这三条记录。

| id   | name   |
| ---- | ------ |
| 1    | first  |
| 99   | second |
| 999  | third  |

当我们在给ｉｄ为９９的记录加gap锁时,它就会限制你在(1,99)这个区间内立即插入任何记录，直到gap锁被释放之后，它会被允许插入。

##### - next_key lock

既锁住当前记录，还要锁住这个记录前面的间隙就需要使用到next_key 锁了，它相当于gap锁和record 锁的合体。既保护了该条记录，还能阻止别的事务将一条记录插入到该条记录的间隙中。

#### - MDL

MDL的全称叫做Mate Data Lock，这是不会被显式使用的一种锁，当我们在访问表的时候会自动加上这把锁。当我们不对数据库的表结构进行修改的时候，它不会有任何作用。但是当我们对表结构做出更改的时候，它的作用就会显现出来。它也可以分为**读锁**和**写锁**，当我们对表进行增删改查的操作时候就会获取MDL的读锁，当我们在对表结构进行修改的时候，它就会加上MDL写锁。和我们的前面说的读写锁一样，**读锁只能和读锁兼容，其他的均不能兼容**。

MDL可能会引起CPU100%的问题。事务A在对表进行一个长事务的时候，事务B对表结构进行修改，这时事务A还没有释放MDL读锁，事务B就会被阻塞。但是如果事务C在阻塞的时候,对表不断的进行增删改查操作这个时候很快就会把CPU打上去,甚至还可能会把线程打满.